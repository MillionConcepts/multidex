{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atmospheric-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import register_cmap\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "\n",
    "import django\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from marslab.imgops.pltutils import attach_axis, despine\n",
    "import matplotlib as mpl\n",
    "from fit import fit_line, plot_mesh, correlation_matrix, Fit, numeric_columns\n",
    "\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"multidex.settings\")\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "django.setup()\n",
    "from marslab.imgops.imgutils import normalize_range\n",
    "import plotter.models\n",
    "from plotter.spectrum_ops import filter_df_from_queryset\n",
    "\n",
    "from marslab.compat.xcam import DERIVED_CAM_DICT\n",
    "\n",
    "from multidex_utils import modeldict, model_metadata_df\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# %matplotlib qt\n",
    "# %matplotlib qt\n",
    "plt.rcParams['font.size'] = '10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fbfc2",
   "metadata": {},
   "source": [
    "tl;dr: \n",
    "1. I'm writing PCA features for MultiDEx. In almost all cases, almost all of the variance is loaded in the first and second principal components, and they are really close to just adding metrics that are (for ZCAM) 'average value of L6 through R0G' and 'average value of L4 through R6'.  and (for MCAM) 'overall ROI brightness' and 'average value of L2 through L0G'. There are some potentially-interesting things out in the tails, but I just wanted to note that vanilla PCA _could_ be questionably useful, and suggest that we should continue exploring different approaches to dimensionality reduction on these data.\n",
    "2. I _think_ we're applying R* 'correctly' everywhere, but I also think that for whatever reason it is making the values more rather than less dependent on 'incidence angle' (which is to say solar elevation). More broadly, I suspect that more granular illumination geometry is a huge latent factor in a lot of these statistics.\n",
    "3. Based on my exchanges with Tina about MCAM I think there are incorrect values in the lookup table I received for\n",
    "\n",
    "\n",
    "the r-star correction definitely makes the effect of incidence angle on reflectance more rather than less pronounced. when applied, incidence angle becomes the single largest determinant of reflectance values rather than a ~20% determinant of reflectance values. this could of course result from shared latent\n",
    "factors. for instance, our corpus is simply not that large and solar elevation varies scene-by-scene; if certain type of observations tend to be performed at certain times of day, for instance, or merely by\n",
    "coincidence have been. and this does seem to be the case -- look at the relatively high correlation between lat, lon, sclk, and incidence angle, all of which should be basically random (or periodic in the case of sclk, but that wouldn't show up here).\n",
    "\n",
    "it's worth noting, though, that even in the larger MCAM corpus, applying r-star seems to make the overall effect of incidence angle more pronunced, although not to the same degree.\n",
    "\n",
    "It could \n",
    "\n",
    "looking at some of the values I got from Tina the other day, I think some of the mappings I have between MCAM ROI colors and feature types might be wrong. Was there a miscommunication about this at some point? If so, do you have a not-wrong version of this table?\n",
    "\n",
    "there is one very large factor that is something like overall ROI brightness; then another that is something like \"blue-greenness'. you can see this in the correlation matrices without any explicit dimensionality reduction -- L6-R0G is one cluster; L4-R6 is another (and L4-R6 has _really_ high internal correlation).\n",
    "\n",
    "This means that a lot of the interesting action is out in the statistical tails -- this is something we know about these data in general, but it really underscores, I think, how important it might be to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bef3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfcbf6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-28acd8fa648a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorr_cmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'orange_teal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minstrument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ZCAM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m spec_model = getattr(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINSTRUMENT_MODEL_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "corr_cmap = 'orange_teal'\n",
    "instrument = 'ZCAM'\n",
    "spec_model = getattr(\n",
    "    plotter.models, \n",
    "    plotter.models.INSTRUMENT_MODEL_MAPPING[instrument]\n",
    ")\n",
    "filter_info = DERIVED_CAM_DICT[instrument]['filters']\n",
    "filts = list(filter_info.keys())\n",
    "narrowband = [filt for filt in filts if len(filt) == 2]\n",
    "metadata_df = model_metadata_df(spec_model)\n",
    "\n",
    "r_star = False\n",
    "# scale_to = ('L1', 'R1')\n",
    "norm_values = False\n",
    "# scale_to = ('L0B', 'R0B')\n",
    "# scale_to = ('L6', 'R6')\n",
    "# scale_to=None\n",
    "data_df = filter_df_from_queryset(\n",
    "    spec_model.objects.all(), r_star=r_star, scale_to=scale_to\n",
    ")\n",
    "corpus = pd.concat([metadata_df, data_df], axis=1)\n",
    "corpus['ltst'] = corpus['ltst'].map(s_from_midnight)\n",
    "corpus['avg'] = corpus[filts].mean(axis=1)\n",
    "explode_field = 'morphology'\n",
    "# explode_field = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fields to do pca on\n",
    "# pca_fields = numeric_columns(search)\n",
    "pca_fields = filts\n",
    "# pca_fields = [band + \"_err\" for band in narrowband]\n",
    "# fields to compare with the PCs \n",
    "# corr_fields = ['incidence_angle', 'lat', 'lon', 'sclk']\n",
    "corr_fields =  filts + ['avg', 'incidence_angle'] + list(exploded.columns)\n",
    "# corr_fields += [band + \"_err\" for band in narrowband]\n",
    "\n",
    "# search_fields = [('feature', 'rock')]\n",
    "# search = search.loc[search['incidence_angle'] > -10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef690003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "corrchart = ax.imshow(correlations, norm=offset, cmap='Spectral')\n",
    "\n",
    "ax.set_yticks(np.arange(len(correlations.index)))\n",
    "ax.set_yticklabels([ix[:4] for ix in correlations.index])\n",
    "ax.set_xticks(np.arange(len(correlations.columns)))\n",
    "ax.set_xticklabels([ix[:4] for ix in correlations.columns])\n",
    "plt.title(\n",
    "    \"{} scaled to {} with R* {}\"\\\n",
    "    .format(instrument, str(scale_to), str(r_star))\n",
    ")\n",
    "cax = attach_axis(ax, 'right', '10%')\n",
    "plt.colorbar(corrchart, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a79b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca069d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9eda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090085c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
    "                                 metric=\"euclidean\", sample_size=300,)\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
    "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\")\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "\n",
    "print(\n",
    "    f\"# digits: {n_digits}; # samples: {n_samples}; # features {n_features}\"\n",
    ")\n",
    "\n",
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=n_digits, n_init=4,\n",
    "                random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=data, labels=labels)\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=n_digits, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"random\", data=data, labels=labels)\n",
    "\n",
    "pca = PCA(n_components=n_digits).fit(data)\n",
    "kmeans = KMeans(init=pca.components_, n_clusters=n_digits, n_init=1)\n",
    "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=data, labels=labels)\n",
    "\n",
    "print(82 * '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = filter_df_from_queryset(ZSpec.objects.all(), r_star=True)\n",
    "data_df.drop(columns=[col for col in data_df.columns if \"err\" in col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-forty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-cartoon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10)\n",
    "metadata_df = model_metadata_df(ZSpec, [\"observation\"])\n",
    "metadata_df['km'] = km.fit_predict(data_df)\n",
    "metadata_df[['feature', 'name', 'km']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-notification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-firmware",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
